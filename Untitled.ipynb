{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', '1', 'cost=', '0.691702276468')\n",
      "('Epoch:', '2', 'cost=', '0.688206364711')\n",
      "('Epoch:', '3', 'cost=', '0.684795657794')\n",
      "('Epoch:', '4', 'cost=', '0.681467006604')\n",
      "('Epoch:', '5', 'cost=', '0.678217361371')\n",
      "('Epoch:', '6', 'cost=', '0.675043731928')\n",
      "('Epoch:', '7', 'cost=', '0.671943426132')\n",
      "('Epoch:', '8', 'cost=', '0.668913741906')\n",
      "('Epoch:', '9', 'cost=', '0.665952205658')\n",
      "('Epoch:', '10', 'cost=', '0.663056373596')\n",
      "('Epoch:', '11', 'cost=', '0.660224010547')\n",
      "('Epoch:', '12', 'cost=', '0.65745289127')\n",
      "('Epoch:', '13', 'cost=', '0.654740989208')\n",
      "('Epoch:', '14', 'cost=', '0.65208619833')\n",
      "('Epoch:', '15', 'cost=', '0.649486770233')\n",
      "('Accuracy:', 0.81132078)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "TRAIN_PATH = \"train.csv\"\n",
    "TEST_PATH = \"test.csv\"\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCH_NUM = 15\n",
    "BATCH_SIZE = 100\n",
    "LOGS_PATH = '/tmp/tensorflow_logs'\n",
    "\n",
    "\n",
    "def preprocess_data(path, is_test=False):\n",
    "    data = pd.read_csv(path, index_col='PassengerId')\n",
    "    data.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "    if is_test:\n",
    "        data = data.replace([None], [0])\n",
    "    else:\n",
    "        data = data[pd.notnull(data['Age'])]\n",
    "        data = data[pd.notnull(data['Embarked'])]\n",
    "    data.replace([\"female\", \"male\"], [0, 1], inplace=True)\n",
    "    data.replace([\"Q\", \"C\", \"S\"], [0, 1, 2], inplace=True)\n",
    "    if \"Survived\" in data:\n",
    "        data = data[pd.notnull(data['Survived'])]\n",
    "    data_norm = (data - data.mean()) / (data.max() - data.min())\n",
    "    return data_norm\n",
    "\n",
    "\n",
    "def next_batch(df, i=None):\n",
    "    \"\"\"\n",
    "\n",
    "    :param df: pandas dataframe\n",
    "    :param i: batch index\n",
    "    :return: (numpy array x, numpy array y)\n",
    "    \"\"\"\n",
    "    if i is None:\n",
    "        start = 0\n",
    "        end = df.shape[0]\n",
    "    else:\n",
    "        start = BATCH_SIZE * i\n",
    "        end = BATCH_SIZE * (i + 1)\n",
    "    result = df[start:end]\n",
    "    if \"Survived\" in result:\n",
    "        batch_ys = pd.get_dummies(result.pop('Survived').values).as_matrix()\n",
    "        batch_xs = result.as_matrix()\n",
    "        return batch_xs, batch_ys\n",
    "    else:\n",
    "        return result.as_matrix()\n",
    "\n",
    "\n",
    "def split_dataset(df, test_part=None):\n",
    "    \"\"\"\n",
    "    Split dataframe\n",
    "    :param test_part: float from 0 to 1\n",
    "    :param df: pandas dataframe\n",
    "    :return: (pandas dataframe train, pandas dataframe test)\n",
    "    \"\"\"\n",
    "    length = df.shape[0]\n",
    "    if test_part is None:\n",
    "        test_part = 0.15\n",
    "\n",
    "    test_part = int(length * test_part)\n",
    "\n",
    "    test_dataset = df[0:test_part]\n",
    "    training_dataset = df[test_part:]\n",
    "    return training_dataset, test_dataset\n",
    "\n",
    "\n",
    "dataset = preprocess_data(TRAIN_PATH)\n",
    "\n",
    "training_dataset, test_narray = split_dataset(dataset)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 7], name='InputData')\n",
    "y = tf.placeholder(tf.float32, [None, 2], name='TargetData')\n",
    "\n",
    "W = tf.Variable(tf.zeros([7, 2]), name='Weights')\n",
    "b = tf.Variable(tf.zeros([2]), name='Bias')\n",
    "\n",
    "with tf.name_scope('Model'):\n",
    "    pred = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "with tf.name_scope('Loss'):\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred + 1e-10), reduction_indices=1))\n",
    "\n",
    "with tf.name_scope('GDS'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cost)\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "    acc = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(acc, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "tf.summary.scalar(\"loss\", cost)\n",
    "tf.summary.scalar(\"accuracy\", acc)\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    log_writer = tf.summary.FileWriter(LOGS_PATH, graph=tf.get_default_graph())\n",
    "    training_dataset_size = training_dataset.shape[0]\n",
    "    for epoch in range(EPOCH_NUM):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(training_dataset_size / BATCH_SIZE)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = next_batch(training_dataset, i)\n",
    "            _, c, summary = sess.run([optimizer, cost, merged_summary], feed_dict={x: batch_xs, y: batch_ys})\n",
    "            log_writer.add_summary(summary, epoch * total_batch + i)\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print(\"Epoch:\", '%d' % (epoch + 1), \"cost=\", \"{0}\".format(avg_cost))\n",
    "\n",
    "    test_x, test_y = next_batch(test_narray)\n",
    "    print(\"Accuracy:\", acc.eval({x: test_x, y: test_y}))\n",
    "\n",
    "    test_df = preprocess_data(TEST_PATH, is_test=True)\n",
    "    indexes = test_df.index.values\n",
    "    test_narray = next_batch(test_df)\n",
    "    feed_dict = {x: test_narray}\n",
    "    predict_proba = pred.eval(feed_dict)\n",
    "    predictions = tf.argmax(predict_proba, dimension=1).eval()\n",
    "\n",
    "    with open(\"kaggle.csv\", \"w\") as f:\n",
    "        f.write(\"PassengerId,Survived\\n\")\n",
    "        for index, prediction in zip(indexes, predictions):\n",
    "            f.write(\"{0},{1}\\n\".format(index, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "target must be a string, but got <class 'tensorflow.python.framework.ops.Operation'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0face5b4f598>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hannarud/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \"\"\"\n\u001b[0;32m-> 1186\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hannarud/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target must be a string, but got %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: target must be a string, but got <class 'tensorflow.python.framework.ops.Operation'>"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session(init) as sess:\n",
    "    sess.run(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
